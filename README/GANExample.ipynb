{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syed001sufiyan/Challenging-Fake-Image-Detection-Using-GAN/blob/main/README/GANExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_mPO--iRYg9T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can change to fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# (28, 28, 1)\n",
        "x_train = x_train.astype(\"float32\").reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "x_train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(x_train)\n",
        "      .batch(BATCH_SIZE, drop_remainder=True)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4TmiGYCaBq5",
        "outputId": "8253507e-7014-482c-ae15-68fe72c94bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates and manages the architectures for the generator and discriminator\n",
        "class GANArchitecture():\n",
        "    def __init__(self, input_shape, num_factors):\n",
        "      self.input_shape = input_shape\n",
        "      self.num_factors = num_factors\n",
        "\n",
        "    def create_generator(self):\n",
        "      model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(100, input_dim = self.num_factors),\n",
        "        tf.keras.layers.LeakyReLU(),\n",
        "        tf.keras.layers.Dense(np.prod(self.input_shape), activation=\"sigmoid\"),\n",
        "        tf.keras.layers.Reshape(self.input_shape)\n",
        "      ])\n",
        "\n",
        "      self.generator = model\n",
        "\n",
        "    def create_discriminator(self):\n",
        "      model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=self.input_shape),\n",
        "        tf.keras.layers.Dense(100),\n",
        "        tf.keras.layers.LeakyReLU(),\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "      ])\n",
        "\n",
        "      self.discriminator = model\n",
        "\n",
        "    def __call__(self):\n",
        "      self.create_generator()\n",
        "      self.create_discriminator()\n",
        "      return self"
      ],
      "metadata": {
        "id": "rB8SccmAbbQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANTrainerModel(tf.keras.models.Model):\n",
        "  def __init__(self, input_shape, num_factors, batch_size):\n",
        "    super(GANTrainerModel, self).__init__()\n",
        "    self.arch = GANArchitecture(input_shape, num_factors)()\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "    self.num_factors = num_factors\n",
        "\n",
        "    self.true_labels = tf.ones((batch_size, 1))\n",
        "    self.false_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "    self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"loss_after_gen\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.loss_tracker, self.gen_loss_tracker]\n",
        "\n",
        "  def compile(self, d_optimizer, g_optimizer, loss):\n",
        "    super(GANTrainerModel, self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss = loss\n",
        "\n",
        "  def train_step(self, data):\n",
        "    # [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
        "    # tf.random.normal NOT tf.random.uniform\n",
        "    rand_factors = tf.random.normal((self.batch_size, self.num_factors))\n",
        "    gen_imgs = self.arch.generator(rand_factors)\n",
        "\n",
        "    disc_data = tf.concat([data, gen_imgs], axis=0)\n",
        "    disc_labels = tf.concat([self.true_labels, self.false_labels], axis=0)\n",
        "\n",
        "    # discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "      disc_pred = self.arch.discriminator(disc_data)\n",
        "      disc_loss = self.loss(disc_labels, disc_pred)\n",
        "\n",
        "    disc_vars = self.arch.discriminator.trainable_variables\n",
        "    disc_gradients = tape.gradient(disc_loss, disc_vars)\n",
        "    self.d_optimizer.apply_gradients(zip(disc_gradients, disc_vars))\n",
        "\n",
        "    # generator\n",
        "    rand_factors = tf.random.normal((self.batch_size, self.num_factors))\n",
        "    trick_labels = self.true_labels\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      gen_imgs = self.arch.generator(rand_factors)\n",
        "      gen_pred = self.arch.discriminator(gen_imgs)\n",
        "      gen_loss = self.loss(trick_labels, gen_pred)\n",
        "\n",
        "    gen_vars = self.arch.generator.trainable_variables\n",
        "    gen_gradients = tape.gradient(gen_loss, gen_vars)\n",
        "    self.d_optimizer.apply_gradients(zip(gen_gradients, gen_vars))\n",
        "\n",
        "    self.loss_tracker.update_state(disc_loss)\n",
        "    self.gen_loss_tracker.update_state(gen_loss)\n",
        "    return {\n",
        "        \"loss\" : self.loss_tracker.result(),\n",
        "        \"gen_loss\": self.gen_loss_tracker.result()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "I1SDgy1LeE7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (28, 28, 1)\n",
        "NUM_FACTORS = 100\n",
        "\n",
        "trainer = GANTrainerModel(INPUT_SHAPE, NUM_FACTORS, BATCH_SIZE)\n",
        "trainer.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    d_optimizer = tf.keras.optimizers.Adam(),\n",
        "    g_optimizer = tf.keras.optimizers.Adam()\n",
        ")"
      ],
      "metadata": {
        "id": "3oUBFp5TivkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(x_train_ds, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RztEpajTjXKq",
        "outputId": "5b8870a6-6aeb-4840-dc54-74cb91369127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "468/468 [==============================] - 7s 7ms/step - loss: 0.0822 - gen_loss: 5.3608\n",
            "Epoch 2/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0387 - gen_loss: 8.9848\n",
            "Epoch 3/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0647 - gen_loss: 5.7729\n",
            "Epoch 4/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1078 - gen_loss: 5.1826\n",
            "Epoch 5/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.0983 - gen_loss: 4.3584\n",
            "Epoch 6/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1500 - gen_loss: 4.2120\n",
            "Epoch 7/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.1628 - gen_loss: 4.1068\n",
            "Epoch 8/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.1711 - gen_loss: 3.8469\n",
            "Epoch 9/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.1907 - gen_loss: 4.0090\n",
            "Epoch 10/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.2020 - gen_loss: 3.9836\n",
            "Epoch 11/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.1955 - gen_loss: 3.8625\n",
            "Epoch 12/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.2421 - gen_loss: 3.5099\n",
            "Epoch 13/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 0.2510 - gen_loss: 3.4197\n",
            "Epoch 14/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.2754 - gen_loss: 3.0089\n",
            "Epoch 15/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.2931 - gen_loss: 3.2303\n",
            "Epoch 16/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.3424 - gen_loss: 3.0080\n",
            "Epoch 17/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.3084 - gen_loss: 3.0828\n",
            "Epoch 18/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.3351 - gen_loss: 2.6720\n",
            "Epoch 19/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.3963 - gen_loss: 2.6901\n",
            "Epoch 20/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 0.3451 - gen_loss: 3.1941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41600de210>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_factors = tf.random.normal((1, NUM_FACTORS))\n",
        "gen_imgs = trainer.arch.generator(rand_factors)"
      ],
      "metadata": {
        "id": "0GxlFHVgkMFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(tf.reshape(gen_imgs, [28, 28]), cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "e4RHiubpkrIi",
        "outputId": "cd73bf6a-33b5-413f-e5fe-cd83c1e524a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f40e2764050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhgAKzNakr5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}